"""
ResNet18èŠ±å‰åˆ†ç±»äº¤äº’å¼æ¼”ç¤ºç³»ç»Ÿ
æ”¯æŒï¼šä¸Šä¼ å›¾ç‰‡é¢„æµ‹ã€å®æ—¶æ‘„åƒå¤´è¯†åˆ«ã€ç»“æœå¯è§†åŒ–ã€æ¨¡å‹è§£é‡Š
"""

import os
import sys
import json
import numpy as np
from pathlib import Path
import base64
from io import BytesIO

# å¯¼å…¥å¿…è¦çš„åº“
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import LinearSegmentedColormap

# Flask/Gradioé›†æˆ
try:
    import gradio as gr
    GRADIO_AVAILABLE = True
except ImportError:
    GRADIO_AVAILABLE = False
    print("Gradioæœªå®‰è£…ï¼Œä½¿ç”¨: pip install gradio")

try:
    from flask import Flask, render_template, request, jsonify
    FLASK_AVAILABLE = True
except ImportError:
    FLASK_AVAILABLE = False

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¯é€‰ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# èŠ±å‰ç±»åˆ«å’Œé¢œè‰²
FLOWER_CLASSES = [
    "Daisy",           # é›èŠ
    "Dandelion",       # è’²å…¬è‹±
    "Rose",            # ç«ç‘°
    "Sunflower",       # å‘æ—¥è‘µ
    "Tulip"            # éƒé‡‘é¦™
]

CLASS_COLORS = {
    "Daisy": "#FFD700",      # é‡‘è‰²
    "Dandelion": "#32CD32",  # ç»¿è‰²
    "Rose": "#FF69B4",       # ç²‰è‰²
    "Sunflower": "#FF8C00",  # æ©™è‰²
    "Tulip": "#9370DB"       # ç´«è‰²
}

class ResNet18FlowerClassifier(nn.Module):
    """ResNet18èŠ±å‰åˆ†ç±»æ¨¡å‹ï¼ˆä¸train.pyä¿æŒä¸€è‡´ï¼‰"""
    
    def __init__(self, num_classes=5, pretrained=True, freeze_layers=True):
        super(ResNet18FlowerClassifier, self).__init__()
        
        # åŠ è½½é¢„è®­ç»ƒResNet18
        self.resnet = models.resnet18(pretrained=pretrained)
        
        # å†»ç»“å‰å‡ å±‚
        if freeze_layers:
            for param in self.resnet.parameters():
                param.requires_grad = False
        
        # ä¿®æ”¹æœ€åä¸€å±‚ï¼ˆä¸train.pyç›¸åŒï¼‰
        num_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        return self.resnet(x)

class FlowerClassifierDemo:
    """èŠ±å‰åˆ†ç±»æ¼”ç¤ºç³»ç»Ÿ"""
    
    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç³»ç»Ÿ
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
        """
        self.device = device
        self.classes = FLOWER_CLASSES
        self.class_colors = CLASS_COLORS
        
        # åŠ è½½æ¨¡å‹
        self.model = self.load_model(model_path)
        self.model.eval()
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼å¯åˆ†ç±»: {', '.join(self.classes)}")
    
    def load_model(self, model_path=None):
        """åŠ è½½æ¨¡å‹"""
        model = ResNet18FlowerClassifier(num_classes=len(self.classes))
        
        if model_path and os.path.exists(model_path):
            print(f"åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
            checkpoint = torch.load(model_path, map_location=self.device)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"æ¨¡å‹å‡†ç¡®ç‡: {checkpoint.get('val_acc', 'N/A')}%")
        else:
            print("ä½¿ç”¨é¢„è®­ç»ƒResNet18ï¼ˆæœªå¾®è°ƒï¼‰")
            # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä½†éœ€è¦ç¡®ä¿æœ€åä¸€å±‚æ­£ç¡®
            model = ResNet18FlowerClassifier(
                num_classes=len(self.classes),
                pretrained=True,
                freeze_layers=False
            )
        
        return model.to(self.device)
    
    def predict(self, image):
        """
        é¢„æµ‹å•å¼ å›¾ç‰‡
        
        Args:
            image: PIL Imageå¯¹è±¡
            
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœå’Œå¯è§†åŒ–ä¿¡æ¯
        """
        # é¢„å¤„ç†
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            
        # è·å–é¢„æµ‹ç»“æœ
        probs = probabilities[0].cpu().numpy()
        predicted_idx = np.argmax(probs)
        predicted_class = self.classes[predicted_idx]
        confidence = probs[predicted_idx]
        
        # åˆ›å»ºå¯è§†åŒ–
        result = {
            'predicted_class': predicted_class,
            'confidence': float(confidence),
            'all_probs': probs.tolist(),
            'visualization': self.create_visualization(image, predicted_class, confidence, probs),
            'gradcam': self.create_gradcam_visualization(image, input_tensor, predicted_idx) if confidence > 0.3 else None
        }
        
        return result
    
    def create_visualization(self, original_img, pred_class, confidence, probs):
        """åˆ›å»ºç»“æœå¯è§†åŒ–å›¾è¡¨"""
        fig = plt.figure(figsize=(14, 6))
        
        # 1. å·¦ä¾§ï¼šåŸå§‹å›¾ç‰‡ + é¢„æµ‹ç»“æœ
        ax1 = plt.subplot(1, 3, 1)
        ax1.imshow(original_img)
        ax1.axis('off')
        
        # æ·»åŠ é¢„æµ‹æ ‡ç­¾
        title_color = self.class_colors.get(pred_class, 'black')
        ax1.set_title(f'é¢„æµ‹: {pred_class}\nç½®ä¿¡åº¦: {confidence*100:.1f}%', 
                     fontsize=14, color=title_color, fontweight='bold')
        
        # 2. ä¸­é—´ï¼šæ¦‚ç‡æ¡å½¢å›¾
        ax2 = plt.subplot(1, 3, 2)
        colors = [self.class_colors.get(cls, '#3498db') for cls in self.classes]
        bars = ax2.barh(self.classes, probs, color=colors, edgecolor='black')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, prob) in enumerate(zip(bars, probs)):
            ax2.text(prob + 0.01, bar.get_y() + bar.get_height()/2, 
                    f'{prob*100:.1f}%', va='center', fontsize=10)
        
        ax2.set_xlabel('æ¦‚ç‡', fontsize=12)
        ax2.set_xlim([0, 1.1])
        ax2.set_title('å„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax2.grid(axis='x', alpha=0.3, linestyle='--')
        
        # 3. å³ä¾§ï¼šç½®ä¿¡åº¦ä»ªè¡¨ç›˜
        ax3 = plt.subplot(1, 3, 3, polar=True)
        
        # åˆ›å»ºä»ªè¡¨ç›˜
        angles = np.linspace(0, 2 * np.pi, len(self.classes), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ
        
        probs_circular = list(probs) + [probs[0]]
        ax3.plot(angles, probs_circular, 'o-', linewidth=2, color='#3498db')
        ax3.fill(angles, probs_circular, alpha=0.25, color='#3498db')
        
        # è®¾ç½®æåæ ‡
        ax3.set_xticks(angles[:-1])
        ax3.set_xticklabels(self.classes, fontsize=10)
        ax3.set_ylim([0, 1])
        ax3.set_yticks([0.25, 0.5, 0.75, 1.0])
        ax3.set_yticklabels(['25%', '50%', '75%', '100%'], fontsize=8)
        ax3.set_title('ç½®ä¿¡åº¦é›·è¾¾å›¾', fontsize=14, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        # ä¿å­˜åˆ°å†…å­˜
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        
        # è½¬æ¢ä¸ºbase64
        img_base64 = base64.b64encode(buf.read()).decode('utf-8')
        return f"data:image/png;base64,{img_base64}"
    
    def create_gradcam_visualization(self, original_img, input_tensor, target_idx):
        """åˆ›å»ºGrad-CAMçƒ­åŠ›å›¾ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # è·å–æœ€åä¸€ä¸ªå·ç§¯å±‚çš„ç‰¹å¾
            features = None
            gradients = None
            
            def save_features(module, input, output):
                nonlocal features
                features = output
            
            def save_gradients(module, grad_in, grad_out):
                nonlocal gradients
                gradients = grad_out[0]
            
            # æ³¨å†Œé’©å­
            target_layer = self.model.resnet.layer4[-1].conv2
            handle_forward = target_layer.register_forward_hook(save_features)
            handle_backward = target_layer.register_full_backward_hook(save_gradients)
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(input_tensor)
            target = outputs[0, target_idx]
            
            # åå‘ä¼ æ’­
            self.model.zero_grad()
            target.backward()
            
            # è®¡ç®—æƒé‡
            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])
            
            # åŠ æƒç‰¹å¾å›¾
            for i in range(features.shape[1]):
                features[:, i, :, :] *= pooled_gradients[i]
            
            heatmap = torch.mean(features, dim=1).squeeze()
            heatmap = torch.nn.functional.relu(heatmap)  # ReLU
            heatmap /= torch.max(heatmap)  # å½’ä¸€åŒ–
            
            # è½¬æ¢ä¸ºnumpy
            heatmap = heatmap.cpu().detach().numpy()
            
            # ç§»é™¤é’©å­
            handle_forward.remove()
            handle_backward.remove()
            
            # åˆ›å»ºçƒ­åŠ›å›¾å åŠ 
            fig, axes = plt.subplots(1, 3, figsize=(12, 4))
            
            # åŸå§‹å›¾ç‰‡
            axes[0].imshow(original_img)
            axes[0].set_title('åŸå§‹å›¾ç‰‡', fontsize=12)
            axes[0].axis('off')
            
            # çƒ­åŠ›å›¾
            im = axes[1].imshow(heatmap, cmap='jet')
            axes[1].set_title('Grad-CAMçƒ­åŠ›å›¾', fontsize=12)
            axes[1].axis('off')
            plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)
            
            # å åŠ å›¾
            original_img_resized = original_img.resize((heatmap.shape[1], heatmap.shape[0]))
            img_array = np.array(original_img_resized) / 255.0
            
            # åˆ›å»ºå åŠ 
            heatmap_resized = np.uint8(255 * heatmap)
            heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]
            
            alpha = 0.5
            superimposed = heatmap_colored * alpha + img_array * (1 - alpha)
            
            axes[2].imshow(superimposed)
            axes[2].set_title('çƒ­åŠ›å›¾å åŠ ', fontsize=12)
            axes[2].axis('off')
            
            plt.tight_layout()
            
            # ä¿å­˜åˆ°å†…å­˜
            buf = BytesIO()
            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
            plt.close(fig)
            buf.seek(0)
            
            # è½¬æ¢ä¸ºbase64
            img_base64 = base64.b64encode(buf.read()).decode('utf-8')
            return f"data:image/png;base64,{img_base64}"
            
        except Exception as e:
            print(f"Grad-CAMç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def batch_predict(self, image_folder):
        """æ‰¹é‡é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡"""
        results = []
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']
        
        for img_file in Path(image_folder).iterdir():
            if img_file.suffix.lower() in image_extensions:
                try:
                    img = Image.open(img_file).convert('RGB')
                    result = self.predict(img)
                    result['filename'] = img_file.name
                    results.append(result)
                except Exception as e:
                    print(f"å¤„ç† {img_file} æ—¶å‡ºé”™: {e}")
        
        return results
    
    def create_summary_report(self, batch_results):
        """åˆ›å»ºæ‰¹é‡é¢„æµ‹æ€»ç»“æŠ¥å‘Š"""
        if not batch_results:
            return None
        
        # ç»Ÿè®¡ä¿¡æ¯
        total = len(batch_results)
        confidences = [r['confidence'] for r in batch_results]
        classes = [r['predicted_class'] for r in batch_results]
        
        # åˆ›å»ºæ€»ç»“å›¾è¡¨
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # 1. ç½®ä¿¡åº¦åˆ†å¸ƒ
        axes[0].hist(confidences, bins=10, color='skyblue', edgecolor='black', alpha=0.7)
        axes[0].axvline(np.mean(confidences), color='red', linestyle='--', label=f'å¹³å‡: {np.mean(confidences):.3f}')
        axes[0].set_xlabel('ç½®ä¿¡åº¦', fontsize=12)
        axes[0].set_ylabel('å›¾ç‰‡æ•°é‡', fontsize=12)
        axes[0].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        axes[0].legend()
        axes[0].grid(alpha=0.3)
        
        # 2. ç±»åˆ«åˆ†å¸ƒ
        from collections import Counter
        class_counts = Counter(classes)
        
        colors = [self.class_colors.get(cls, '#3498db') for cls in class_counts.keys()]
        bars = axes[1].bar(class_counts.keys(), class_counts.values(), color=colors, edgecolor='black')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, class_counts.values()):
            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                        str(count), ha='center', va='bottom', fontsize=10)
        
        axes[1].set_xlabel('èŠ±å‰ç±»åˆ«', fontsize=12)
        axes[1].set_ylabel('å›¾ç‰‡æ•°é‡', fontsize=12)
        axes[1].set_title('é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        axes[1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ä¿å­˜åˆ°å†…å­˜
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        
        # è½¬æ¢ä¸ºbase64
        img_base64 = base64.b64encode(buf.read()).decode('utf-8')
        
        # åˆ›å»ºæ€»ç»“æ–‡æœ¬
        summary = {
            'total_images': total,
            'avg_confidence': float(np.mean(confidences)),
            'class_distribution': dict(class_counts),
            'top_class': max(class_counts, key=class_counts.get),
            'report_chart': f"data:image/png;base64,{img_base64}"
        }
        
        return summary

# ==================== Gradioç•Œé¢ ====================
if GRADIO_AVAILABLE:
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    classifier = FlowerClassifierDemo(model_path='checkpoints/best_model.pth')
    
    # ç¤ºä¾‹å›¾ç‰‡
    example_images = [
        ["sample_images/daisy.jpg", "é›èŠç¤ºä¾‹"],
        ["sample_images/rose.jpg", "ç«ç‘°ç¤ºä¾‹"],
        ["sample_images/sunflower.jpg", "å‘æ—¥è‘µç¤ºä¾‹"],
        ["sample_images/tulip.jpg", "éƒé‡‘é¦™ç¤ºä¾‹"],
        ["sample_images/dandelion.jpg", "è’²å…¬è‹±ç¤ºä¾‹"]
    ]
    
    # è‡ªå®šä¹‰CSS
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .output-image img {
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .success-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
    }
    .result-box {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #3498db;
        margin: 10px 0;
    }
    """
    
    def predict_interface(image):
        """Gradioé¢„æµ‹æ¥å£"""
        if image is None:
            return None, None, "è¯·ä¸Šä¼ å›¾ç‰‡"
        
        try:
            # è½¬æ¢ä¸ºPIL Image
            if isinstance(image, str):
                img = Image.open(image)
            else:
                img = Image.fromarray(image)
            
            # é¢„æµ‹
            result = classifier.predict(img)
            
            # åˆ›å»ºHTMLç»“æœ
            html_result = f"""
            <div class="success-box">
                <h3>ğŸŒº é¢„æµ‹ç»“æœ</h3>
                <p><strong>èŠ±å‰ç§ç±»:</strong> {result['predicted_class']}</p>
                <p><strong>ç½®ä¿¡åº¦:</strong> {result['confidence']*100:.2f}%</p>
                <p><strong>æ¨¡å‹:</strong> ResNet18 (84.13%æµ‹è¯•å‡†ç¡®ç‡)</p>
            </div>
            
            <div class="result-box">
                <h4>ğŸ“Š è¯¦ç»†æ¦‚ç‡:</h4>
                <table style="width:100%">
            """
            
            for cls, prob in zip(classifier.classes, result['all_probs']):
                color = classifier.class_colors.get(cls, '#3498db')
                bar_width = prob * 100
                html_result += f"""
                <tr>
                    <td style="width:30%"><strong>{cls}</strong></td>
                    <td style="width:60%">
                        <div style="background:#e0e0e0; height:20px; border-radius:10px;">
                            <div style="background:{color}; width:{bar_width}%; height:20px; border-radius:10px;"></div>
                        </div>
                    </td>
                    <td style="width:10%; text-align:right">{prob*100:.1f}%</td>
                </tr>
                """
            
            html_result += """
                </table>
            </div>
            
            <div class="result-box">
                <h4>â„¹ï¸ æ¨¡å‹ä¿¡æ¯:</h4>
                <ul>
                    <li><strong>æ¶æ„:</strong> ResNet18 with Transfer Learning</li>
                    <li><strong>è®­ç»ƒæ•°æ®:</strong> Kaggle Flowers Recognition (5ç±»)</li>
                    <li><strong>æµ‹è¯•å‡†ç¡®ç‡:</strong> 84.13%</li>
                    <li><strong>è®­ç»ƒæ—¶é—´:</strong> 31.2åˆ†é’Ÿ</li>
                </ul>
            </div>
            """
            
            # è¿”å›ç»“æœ
            return result['visualization'], html_result
            
        except Exception as e:
            return None, None, f"é¢„æµ‹å‡ºé”™: {str(e)}"
    
    def create_gradio_app():
        """åˆ›å»ºGradioåº”ç”¨"""
        with gr.Blocks(title="ResNet18èŠ±å‰åˆ†ç±»æ¼”ç¤º", css=custom_css) as demo:
            gr.Markdown("# ğŸŒ¸ ResNet18èŠ±å‰åˆ†ç±»æ¼”ç¤ºç³»ç»Ÿ")
            gr.Markdown("""
            ### ä¸Šä¼ èŠ±æœµå›¾ç‰‡ï¼Œä½“éªŒæ·±åº¦å­¦ä¹ åˆ†ç±»æ¨¡å‹
            - **æ¨¡å‹**: ResNet18 with Transfer Learning
            - **å‡†ç¡®ç‡**: 84.13% on test set
            - **è®­ç»ƒæ•°æ®**: Kaggle Flowers Recognition (5 classes)
            - **æ”¯æŒ**: å•å›¾é¢„æµ‹ã€æ‰¹é‡å¤„ç†ã€æ¨¡å‹è§£é‡Š
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    # è¾“å…¥ç»„ä»¶
                    image_input = gr.Image(
                        type="pil", 
                        label="ä¸Šä¼ èŠ±æœµå›¾ç‰‡",
                        height=300,
                        sources=["upload", "clipboard", "webcam"]
                    )
                    
                    gr.Examples(
                        examples=example_images,
                        inputs=image_input,
                        label="ç¤ºä¾‹å›¾ç‰‡",
                        examples_per_page=3
                    )
                    
                    submit_btn = gr.Button("ğŸš€ å¼€å§‹åˆ†ç±»", variant="primary", size="lg")
                    
                    # æ‰¹é‡å¤„ç†
                    with gr.Accordion("ğŸ“ æ‰¹é‡å¤„ç†ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰", open=False):
                        folder_input = gr.File(
                            label="é€‰æ‹©å¤šä¸ªå›¾ç‰‡æ–‡ä»¶",
                            file_count="multiple",
                            file_types=["image"]
                        )
                        batch_btn = gr.Button("æ‰¹é‡å¤„ç†", variant="secondary")
                
                with gr.Column(scale=1):
                    # è¾“å‡ºç»„ä»¶
                    output_image = gr.Image(
                        label="é¢„æµ‹ç»“æœå¯è§†åŒ–",
                        height=400,
                        interactive=False
                    )
                    
                    output_html = gr.HTML(
                        label="è¯¦ç»†ç»“æœ",
                        value="<div style='padding:20px;text-align:center;color:#666;'>ç­‰å¾…å›¾ç‰‡ä¸Šä¼ ...</div>"
                    )
            
            # æ¨¡å‹è§£é‡Šéƒ¨åˆ†
            with gr.Accordion("ğŸ” æ¨¡å‹è§£é‡Šä¸å¯è§†åŒ–", open=False):
                gr.Markdown("""
                ### Grad-CAM å¯è§†åŒ–
                Grad-CAM (Gradient-weighted Class Activation Mapping) æ˜¾ç¤ºæ¨¡å‹å…³æ³¨çš„å›¾åƒåŒºåŸŸã€‚
                çƒ­åŠ›å›¾æ˜¾ç¤ºæ¨¡å‹åœ¨åšå‡ºå†³ç­–æ—¶å…³æ³¨çš„å›¾åƒéƒ¨åˆ†ã€‚
                """)
                
                cam_output = gr.Image(
                    label="Grad-CAMçƒ­åŠ›å›¾",
                    interactive=False
                )
            
            # é¡¹ç›®ä¿¡æ¯
            with gr.Accordion("ğŸ“š é¡¹ç›®ä¿¡æ¯", open=False):
                gr.Markdown("""
                ### é¡¹ç›®è¯¦æƒ…
                - **GitHubä»“åº“**: [ResNet18-Flower-Classification](https://github.com/Yyyyuan1029/ResNet18-Flower-Classification1.0)
                - **å®Œæ•´æŠ¥å‘Š**: [Final Report PDF](Final_report_template.pdf)
                - **å›¢é˜Ÿæˆå‘˜**: Siyuan Luo, Yuran Li
                - **è¯¾ç¨‹**: Macau University of Science and Technology, CS460/EIE460/SE460
                
                ### æŠ€æœ¯æ ˆ
                - **æ·±åº¦å­¦ä¹ æ¡†æ¶**: PyTorch 1.13
                - **Webæ¡†æ¶**: Gradio 4.0+
                - **å¯è§†åŒ–**: Matplotlib, Seaborn
                - **æ•°æ®å¤„ç†**: NumPy, PIL
                
                ### æ¨¡å‹æ€§èƒ½
                | æŒ‡æ ‡ | å€¼ |
                |------|-----|
                | æµ‹è¯•å‡†ç¡®ç‡ | 84.13% |
                | æœ€ä½³éªŒè¯å‡†ç¡®ç‡ | 85.98% |
                | è®­ç»ƒæ—¶é—´ | 31.2åˆ†é’Ÿ |
                | æ¨¡å‹å¤§å° | 44.7 MB |
                """)
            
            # äº‹ä»¶ç»‘å®š
            submit_btn.click(
                fn=predict_interface,
                inputs=[image_input],
                outputs=[output_image, output_html]
            )
            
            # æ‰¹é‡å¤„ç†åŠŸèƒ½
            def batch_process(files):
                if not files:
                    return None, "è¯·é€‰æ‹©æ–‡ä»¶"
                
                results = []
                for file in files:
                    try:
                        img = Image.open(file.name).convert('RGB')
                        result = classifier.predict(img)
                        results.append({
                            'filename': os.path.basename(file.name),
                            'class': result['predicted_class'],
                            'confidence': f"{result['confidence']*100:.1f}%"
                        })
                    except Exception as e:
                        results.append({
                            'filename': os.path.basename(file.name),
                            'class': 'é”™è¯¯',
                            'confidence': str(e)
                        })
                
                # åˆ›å»ºç»“æœè¡¨æ ¼
                html_table = """
                <div style="background:#f8f9fa;padding:20px;border-radius:10px;">
                    <h3>æ‰¹é‡å¤„ç†ç»“æœ</h3>
                    <table style="width:100%;border-collapse:collapse;">
                        <tr style="background:#3498db;color:white;">
                            <th style="padding:10px;text-align:left;">æ–‡ä»¶å</th>
                            <th style="padding:10px;text-align:left;">é¢„æµ‹ç±»åˆ«</th>
                            <th style="padding:10px;text-align:left;">ç½®ä¿¡åº¦</th>
                        </tr>
                """
                
                for i, result in enumerate(results):
                    bg_color = "#ffffff" if i % 2 == 0 else "#f2f2f2"
                    color = classifier.class_colors.get(result['class'], '#666666')
                    
                    html_table += f"""
                    <tr style="background:{bg_color};">
                        <td style="padding:10px;border-bottom:1px solid #ddd;">{result['filename']}</td>
                        <td style="padding:10px;border-bottom:1px solid #ddd;">
                            <span style="color:{color};font-weight:bold;">{result['class']}</span>
                        </td>
                        <td style="padding:10px;border-bottom:1px solid #ddd;">{result['confidence']}</td>
                    </tr>
                    """
                
                html_table += "</table></div>"
                return None, html_table
            
            batch_btn.click(
                fn=batch_process,
                inputs=[folder_input],
                outputs=[output_image, output_html]
            )
        
        return demo
    
    # è¿è¡ŒGradioåº”ç”¨
    def run_gradio():
        demo = create_gradio_app()
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=True,  # åˆ›å»ºå…¬å¼€é“¾æ¥
            debug=False,
            show_error=True
        )
    
    # ä¸»å‡½æ•°
    if __name__ == "__main__":
        print("=" * 60)
        print("ğŸŒº ResNet18èŠ±å‰åˆ†ç±»æ¼”ç¤ºç³»ç»Ÿ")
        print("=" * 60)
        print(f"æ¨¡å‹è®¾å¤‡: {device}")
        print(f"å¯åˆ†ç±»: {', '.join(FLOWER_CLASSES)}")
        print("\nè®¿é—®åœ°å€:")
        print("æœ¬åœ°: http://localhost:7860")
        print("å…¬å¼€é“¾æ¥å°†åœ¨å¯åŠ¨åæ˜¾ç¤º")
        print("=" * 60)
        
        run_gradio()

else:
    print("è¯·å…ˆå®‰è£…Gradio: pip install gradio")
    print("æˆ–ä½¿ç”¨Flaskç‰ˆæœ¬ï¼Œè¿è¡Œ: python demo/app_flask.py")